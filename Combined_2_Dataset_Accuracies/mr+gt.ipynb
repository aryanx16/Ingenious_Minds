{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  

  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets scikit-learn accelerate"
      ],
      "metadata": {
        "id": "KIe3snR-J2_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    set_seed\n",
        ")\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "7rXAXlBL9rca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uN4fyt8_9s3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f20aab6-047f-44e2-c87a-d8d09b203751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mr_train_df = pd.read_csv(\"/content/drive/MyDrive/L3Cube/L3Cube-MahaSent-MD/MahaSent_MR/MahaSent_MR_Train.csv\")\n",
        "mr_val_df = pd.read_csv(\"/content/drive/MyDrive/L3Cube/L3Cube-MahaSent-MD/MahaSent_MR/MahaSent_MR_Val.csv\")\n",
        "mr_test_df = pd.read_csv('/content/drive/MyDrive/L3Cube/L3Cube-MahaSent-MD/MahaSent_MR/MahaSent_MR_Test.csv')\n",
        "gt_train_df = pd.read_csv(\"/content/drive/MyDrive/L3Cube/L3Cube-MahaSent-MD/MahaSent_GT/tweets-train.csv\")\n",
        "gt_val_df = pd.read_csv(\"/content/drive/MyDrive/L3Cube/L3Cube-MahaSent-MD/MahaSent_GT/tweets-valid.csv\")\n",
        "gt_test_df = pd.read_csv('/content/drive/MyDrive/L3Cube/L3Cube-MahaSent-MD/MahaSent_GT/tweets-test.csv')"
      ],
      "metadata": {
        "id": "KrnKB94F9zQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mr_train_df.head())\n",
        "print(\"\\n\")\n",
        "print(gt_train_df.head())"
      ],
      "metadata": {
        "id": "YwC2EPSMBuV7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39fce060-3137-4967-b9f1-56ef36ad7b24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0                                   marathi_sentence  label\n",
            "0           0  माने यांचा घटस्फोट झाला आहे तर मोहितेने नुकतेच...     -1\n",
            "1           1  एका रात्रीत घडणारी किंबहुना बिघडणारी ही गोष्ट आहे     -1\n",
            "2           2  जरी आघात समजण्यायोग्य आहे जरी चित्रपटाला खराब ...     -1\n",
            "3           3  पण तो असा आघातही अनुभवत आहे की तो कोणाशीही शेअ...     -1\n",
            "4           4               छोटे-छोटे गैरसमज मोठ्या अडचणीत येतात     -1\n",
            "\n",
            "\n",
            "                                               tweet  label  political\n",
            "0          होता होता राहीलेला  निवडणूक मारो मर्ज़ीभई     -1          0\n",
            "1                         खरा लखोबा तर हा बोबडाच आहे     -1         -1\n",
            "2  मुंबईतील घाटकोपरमध्ये धुळवड खेळून घरी परतलेलं ...     -1          0\n",
            "3      वेडाबाई भूतकाळ बघ लोक शेन घालतात आणी दांडा ही     -1         -1\n",
            "4  कुर्ला वाहतुक विभागाला फक्त हे पाठवले जाते पण ...     -1         -1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize column names by renaming text fields to 'text'\n",
        "\n",
        "#Training\n",
        "mr_train_df = mr_train_df.rename(columns={\"marathi_sentence\": \"text\"})\n",
        "gt_train_df = gt_train_df.rename(columns={\"tweet\": \"text\"})\n",
        "mr_train_df = mr_train_df[[\"text\", \"label\"]]\n",
        "gt_train_df = gt_train_df[[\"text\", \"label\"]]\n",
        "\n",
        "# Combine MR and PT datasets into a single train dataframe\n",
        "train_df = pd.concat([mr_train_df, gt_train_df], ignore_index=True)\n",
        "\n",
        "# Shuffle the datasets to avoid ordering bias during training\n",
        "train_df = train_df.sample(frac=1, random_state=42)"
      ],
      "metadata": {
        "id": "KYIRQ-_VBuu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#similarly for validation and test\n",
        "# Validation\n",
        "mr_val_df = mr_val_df.rename(columns={\"marathi_sentence\": \"text\"})\n",
        "gt_val_df = gt_val_df.rename(columns={\"tweet\": \"text\"})\n",
        "val_df = pd.concat([mr_val_df[[\"text\", \"label\"]], gt_val_df[[\"text\", \"label\"]]], ignore_index=True)\n",
        "val_df = val_df.sample(frac=1, random_state=42)\n",
        "# Test\n",
        "mr_test_df = mr_test_df.rename(columns={\"marathi_sentence\": \"text\"})\n",
        "gt_test_df = gt_test_df.rename(columns={\"tweet\": \"text\"})\n",
        "test_df = pd.concat([mr_test_df[[\"text\", \"label\"]], gt_test_df[[\"text\", \"label\"]]], ignore_index=True)\n",
        "test_df = test_df.sample(frac=1, random_state=42)\n"
      ],
      "metadata": {
        "id": "wi7mm_imCAko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert original sentiment labels to numeric IDs for model training\n",
        "# Also ensure 'text' column contains only strings and handle NaN values\n",
        "\n",
        "for df in [train_df, val_df, test_df]:\n",
        "    df[\"label\"] = df[\"label\"].astype(int)\n",
        "    df[\"label\"] = df[\"label\"] + 1  # -1->0, 0->1, 1->2\n",
        "    df[\"text\"] = df[\"text\"].astype(str).fillna(\"\") # Ensure text is string and handle NaNs"
      ],
      "metadata": {
        "id": "EaRv6hMmCLnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert pandas dataframes into HuggingFace Dataset objects\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset   = Dataset.from_pandas(val_df)\n",
        "test_dataset  = Dataset.from_pandas(test_df)\n"
      ],
      "metadata": {
        "id": "K0zlNDysCORt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize text: pad, truncate, and encode inputs for BERT\n",
        "\n",
        "def tokenize_fn(batch):\n",
        "    # Ensure each text item is explicitly a string within a list for tokenizer compatibility\n",
        "    texts = [str(x) for x in batch[\"text\"]]\n",
        "    return tokenizer(\n",
        "        texts,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128\n",
        "    )"
      ],
      "metadata": {
        "id": "gN5KJTESCQdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Marathi-BERT-v2 tokenizer and model for sequence classification\n",
        "\n",
        "model_name = \"l3cube-pune/marathi-bert-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)  # 3 labels: pos/neg/neutral"
      ],
      "metadata": {
        "id": "FlUuI-49CWyw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368,
          "referenced_widgets": [
            "ea763a0a0c5a46f0bd38a873547bffe4",
            "c976aa1b40bb4748a9897be369261073",
            "61bf87a4cbd04cc79c4f0845b31220a4",
            "10b0e907d7ea4d029443303bb81d712c",
            "af9aae7431da48719fa1d5e9ca1bc102",
            "4f57e9bbf89c4b80bddde3c659f6f911",
            "396d7a2428454922a8c1e2d9bc77c26d",
            "83e2b394183d4b2f8ec6efbe5baacca4",
            "71d6fc1f73ac49428e937e7254ef1bb2",
            "78408b254ead4d20a662d3af951012d5",
            "b459da4bec504140afa58fe57f9a96ce",
            "8f937c1336fb4aa382f11891c87e248e",
            "71b489bbd4ec42ba8bed0513e7e41113",
            "6bfc941ae21949f7a59eebf136220b60",
            "5c664396fd73414d9bc5cc70337c984a",
            "a4737e862a504c4e8a4c9d55fd87025d",
            "c951a6b0a3d4433b879fa6fa2119cabb",
            "22e7d6f57bf94f6a857d65d37cd63edf",
            "b6896ce72f6d4289a378e040a81410c5",
            "0283a8ee0f5040aaac3401c187898bd7",
            "74e1300730204662aac95d4fcd26669d",
            "889e8dc333e6493c83194c00333d7f66",
            "ed814e5205c941578753b8160a52d184",
            "70250cc9dbf24d9594ddb27cfa68ad8f",
            "242d329ebf594e3babc7c87ca4e5c464",
            "61f13c4aeb2c43ed9e6cdeee5b392eab",
            "132f3f20b489489dae8219b194e8903b",
            "8034010d7d744a5a8e482cefbeba4a03",
            "b519cf3bc61546288b8d11c17f821c5d",
            "45ddf9eb096c46b7a344a8e50fe56229",
            "e3072ed1c21840359ba4fa8fe177a905",
            "5c0cfe5d41e542218e1b42d286ff8e09",
            "612100e1b539479db8b648b33a60960a",
            "5e86355feeff4cba900a04dbeaa809db",
            "29ab63a239d84ce081ec1f01b9198b34",
            "08932add706e4d669df017a0c389e597",
            "68084dd36e7048a4920d30782c4f2bf2",
            "fba6040c8ffe4ab1949a390759c316b5",
            "b45af0d5a0f3478a8ad3b7f8547ae9a7",
            "bb54d74be4d24b218c4d2faeac7a3893",
            "d26042079a9f4d16a579df94107c810b",
            "1ccffceacfad406e8d44c93abee0a10e",
            "cabcb0091805464096dc9e1e55ff940f",
            "375e9ffa6000475e9384c1adf3a7d713",
            "304771d82fef472286bf11a532d82ae2",
            "b86babc47c45457bb16d3e6ef5ec4f73",
            "276a7598c56644c0a7f0c39cf5b21a36",
            "d45b2d2dbd0945c9b7dbcc260608582d",
            "616fe7a1741b4cccb3e3217b3b2df768",
            "fdbaff07896849e98ef9f625a84bbf69",
            "0a563d354b494ea2b5c1a85dcadb5a83",
            "72c2b19b15ae4fe09fe72d732494b2a0",
            "f826d7dd52734d17a347a7a1f606b756",
            "f82ba1a4624a4ae2b883ae597df6d877",
            "cbcc5e0781f5400ebbcf9b8c810695ee",
            "21fb2aa11d5c4ccea4f3dbb17d28bd6a",
            "88a6f1689fab47bc995b51f3e6701c2b",
            "336ae94d76564bf6bf530a78c06d12b5",
            "72e4cf1bc8d94654bbb5f1a9ebae8f6b",
            "2cfe681ad80d49e3bdb25f2dd590b3ee",
            "2d0a0629ddb444fdbb29ac1dbc760225",
            "f6f6385965074c9e89d9586c456cec60",
            "f217a0d1400542809364479fc071c84f",
            "d63c756dea1c460d8364f4514997931d",
            "85b32630c1454f93aa98cdf3f5a7b305",
            "ff5f08f4bb5a4d3d809f64be0604a35b"
          ]
        },
        "outputId": "1f00bf3e-9169-4361-8add-0ffd91a05546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/455 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea763a0a0c5a46f0bd38a873547bffe4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f937c1336fb4aa382f11891c87e248e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed814e5205c941578753b8160a52d184"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e86355feeff4cba900a04dbeaa809db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "304771d82fef472286bf11a532d82ae2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/951M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21fb2aa11d5c4ccea4f3dbb17d28bd6a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at l3cube-pune/marathi-bert-v2 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_encoded = train_dataset.map(tokenize_fn, batched=True)\n",
        "val_encoded   = val_dataset.map(tokenize_fn, batched=True)\n",
        "test_encoded  = test_dataset.map(tokenize_fn, batched=True)"
      ],
      "metadata": {
        "id": "XayVSMLKCZ4J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "309fb8198b324eccbcda0cc96ece0b73",
            "c13e37433e87423b8977d2e32dab6626",
            "72f54324d18448338ff335a40b82003b",
            "ab1a1a3b1c344d1e9e8c020b4337ce75",
            "d3c92b06b49143818977686b4824d11d",
            "827b5d5d9aa6460382b62df5049f5581",
            "60b8d67de226448d9e3e731a3539988c",
            "ad1bfd67e9854297b54d5ccbb397fff5",
            "cbaee0e5b33c412997d9b9f114755172",
            "7e0518daf3a24f65aa44a1f282688382",
            "44e9644f57f64fa08136af0540c78f76",
            "f3bc8b2ee5ef4d25b6eb57d2c99ec63d",
            "e29027ab29ca47b5aab6cf81d2d012ec",
            "d834defcd0be430584753bb03c490813",
            "9aee89ec9cd344009bb6bbf4159d4d44",
            "7de6904ac97d40379de2862c340ab379",
            "edf2d951c6864906a423e56be0820bcd",
            "be7d65f6f28a4594bba88036328ea63e",
            "6ab3ba16b5384c90ac25ef8a5c861a38",
            "683df7022d5c4d5dbd845a555b906abd",
            "dc47d958d0f145d5b55950d0f0aa5135",
            "f1f53e5df9f14685af04aa9b5ce171cd",
            "ab63ddcaec574ec184da84fb59e4ee06",
            "3da23447deed4af0ac1d6c10c820e906",
            "3b7248eaba3344429e92abbf8b9ac17d",
            "b09e818abc5d45b9a2733f60440c6518",
            "14ffbdf52b2548e7b91795ae6e204681",
            "41eca5c294f24a10a2ae89ffe20a97cd",
            "3451d357aac641fbbef14f3dcaac0b70",
            "f1de05d117a7487c860256f6e2402199",
            "1bb647b3033040869abd4b509b1548bd",
            "f97648fa18ec4a8cb64b35e14280115e",
            "5bdd9ecf2e074a1f821093df6836361b"
          ]
        },
        "outputId": "ad31862a-30d5-4909-ca22-eee306c7e77b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/24000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "309fb8198b324eccbcda0cc96ece0b73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3bc8b2ee5ef4d25b6eb57d2c99ec63d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab63ddcaec574ec184da84fb59e4ee06"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=3\n",
        ")\n"
      ],
      "metadata": {
        "id": "8ogDMeQsCjts",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0425599b-f7dd-491b-b564-a07c994e9bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at l3cube-pune/marathi-bert-v2 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define accuracy, precision, recall, and F1 score metrics\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = np.argmax(pred.predictions, axis=1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(labels, preds),\n",
        "        \"precision_macro\": precision_score(labels, preds, average=\"macro\", zero_division=0),\n",
        "        \"recall_macro\": recall_score(labels, preds, average=\"macro\", zero_division=0),\n",
        "        \"f1_macro\": f1_score(labels, preds, average=\"macro\", zero_division=0),\n",
        "    }"
      ],
      "metadata": {
        "id": "WG0xC3F0DR1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure training parameters such as epochs, batch size, and learning rate\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./mr_gt_marathi_bert_v2\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    logging_steps=50,\n",
        "    fp16=True,             # if your GPU supports it\n",
        "    report_to=\"none\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "BAnK61OsDU1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Trainer and begin fine-tuning Marathi-BERT-v2\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_encoded,\n",
        "    eval_dataset=val_encoded,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n"
      ],
      "metadata": {
        "id": "zq_74cu-DZmG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3987227b-b720-413c-ad6c-a751b5e141e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3285206523.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "XkAFYO2xDdcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a2ba8eb3-18db-4b69-8422-ec228a9b4280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4500' max='4500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4500/4500 14:15, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision Macro</th>\n",
              "      <th>Recall Macro</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.542000</td>\n",
              "      <td>0.545815</td>\n",
              "      <td>0.786333</td>\n",
              "      <td>0.785958</td>\n",
              "      <td>0.786333</td>\n",
              "      <td>0.784473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.445900</td>\n",
              "      <td>0.518793</td>\n",
              "      <td>0.799667</td>\n",
              "      <td>0.797757</td>\n",
              "      <td>0.799667</td>\n",
              "      <td>0.798241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.325900</td>\n",
              "      <td>0.556392</td>\n",
              "      <td>0.795667</td>\n",
              "      <td>0.794796</td>\n",
              "      <td>0.795667</td>\n",
              "      <td>0.795169</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4500, training_loss=0.5074388569725884, metrics={'train_runtime': 856.8408, 'train_samples_per_second': 84.03, 'train_steps_per_second': 5.252, 'total_flos': 4736041519104000.0, 'train_loss': 0.5074388569725884, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the fine-tuned model on the combined test set\n",
        "\n",
        "test_metrics = trainer.evaluate(test_encoded)\n",
        "print(\"Test metrics:\", test_metrics)\n"
      ],
      "metadata": {
        "id": "mkYpisRGDfUZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "ee9e35d6-420d-462e-de70-568a4f7d75ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='188' max='188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [188/188 00:09]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test metrics: {'eval_loss': 0.5209537148475647, 'eval_accuracy': 0.7986666666666666, 'eval_precision_macro': 0.7971436629844081, 'eval_recall_macro': 0.7986666666666666, 'eval_f1_macro': 0.7973552451382195, 'eval_runtime': 9.5265, 'eval_samples_per_second': 314.912, 'eval_steps_per_second': 19.734, 'epoch': 3.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QsihBIa9Sqr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48053d13"
      },
      "source": [
        "### **Evaluate on MahaSent_MR Test Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106,
          "referenced_widgets": [
            "efeb45ceb02e47c6a9b5be86548bb94b",
            "8d3bb78e362a4f988a64379f83614259",
            "7684e8b307174668a7b3393d3752f3a8",
            "bf6b236bf4da44d7bf17f1291b47279e",
            "90d5dcd096fa465e9785d584b7652406",
            "af2d472b57934227b47d36ce8ce7285b",
            "4b85eea712c849478a4fc64c6b04db9b",
            "02cf2eba28764713a81661746bbca3d6",
            "e0b08c4e125d440f824b2a88d1bb6df8",
            "b3dfb64f3bc140f394c50e111ec92dc5",
            "5463be8030074172ab9cd580d9009e8e"
          ]
        },
        "id": "40c1a4fa",
        "outputId": "c47a588f-beee-4de5-fc63-4ff7c5160031"
      },
      "source": [
        "mr_test_df_processed = mr_test_df.copy()\n",
        "mr_test_df_processed['label'] = mr_test_df_processed['label'].astype(int)\n",
        "mr_test_df_processed['label'] = mr_test_df_processed['label'] + 1 # -1->0, 0->1, 1->2\n",
        "mr_test_df_processed['text'] = mr_test_df_processed['text'].astype(str).fillna('')\n",
        "mr_test_dataset = Dataset.from_pandas(mr_test_df_processed)\n",
        "mr_test_encoded = mr_test_dataset.map(tokenize_fn, batched=True)\n",
        "\n",
        "mr_test_metrics = trainer.evaluate(mr_test_encoded)\n",
        "print(\"MahaSent_MR Test metrics:\", mr_test_metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efeb45ceb02e47c6a9b5be86548bb94b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='470' max='188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [188/188 34:47]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MahaSent_MR Test metrics: {'eval_loss': 0.5146344900131226, 'eval_accuracy': 0.808, 'eval_precision_macro': 0.8085617122508015, 'eval_recall_macro': 0.8079999999999999, 'eval_f1_macro': 0.8060873757675299, 'eval_runtime': 3.382, 'eval_samples_per_second': 443.528, 'eval_steps_per_second': 27.794, 'epoch': 3.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ec4fd4c"
      },
      "source": [
        "### **Evaluate on MahaSent_GT Test Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106,
          "referenced_widgets": [
            "5306152cece146b296ec7460220ea253",
            "1c1d119576094df18afa289cf348c03e",
            "317c30a677584f1dbe9b3cb823db927f",
            "b7d2641a122a481589fb014d0e4ba389",
            "0de66a3b615347c1a731d037ea24d580",
            "20eafe852de04e3c9664795dcc69b0d7",
            "36aad8b1a0d546a3a86e651b34767741",
            "520caccc78274049a187a576f502187a",
            "0e0e6915189148cfa51bbbd2547fcab0",
            "90530da04f9440288b548433c68dea72",
            "f9ef287f7b054fa5903e24f728a794af"
          ]
        },
        "id": "e6df7959",
        "outputId": "1ad199d8-2bc9-4e5a-f453-5ffd777f8cea"
      },
      "source": [
        "gt_test_df_processed = gt_test_df.copy()\n",
        "gt_test_df_processed['label'] = gt_test_df_processed['label'].astype(int)\n",
        "gt_test_df_processed['label'] = gt_test_df_processed['label'] + 1 # -1->0, 0->1, 1->2\n",
        "gt_test_df_processed['text'] = gt_test_df_processed['text'].astype(str).fillna('')\n",
        "gt_test_dataset = Dataset.from_pandas(gt_test_df_processed)\n",
        "gt_test_encoded = gt_test_dataset.map(tokenize_fn, batched=True)\n",
        "\n",
        "gt_test_metrics = trainer.evaluate(gt_test_encoded)\n",
        "print(\"MahaSent_GT Test metrics:\", gt_test_metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5306152cece146b296ec7460220ea253"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='564' max='188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [188/188 34:53]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MahaSent_GT Test metrics: {'eval_loss': 0.5272725224494934, 'eval_accuracy': 0.7893333333333333, 'eval_precision_macro': 0.7893222951367936, 'eval_recall_macro': 0.7893333333333333, 'eval_f1_macro': 0.7893242452004378, 'eval_runtime': 3.1493, 'eval_samples_per_second': 476.29, 'eval_steps_per_second': 29.847, 'epoch': 3.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5xbiv9OxbenQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "918370c7"
      },
      "source": [
        "### **Evaluate on MahaSent_ST Test Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5120d7cb",
        "outputId": "9d50214f-bc06-4cc7-9b79-5e548510ef51"
      },
      "source": [
        "st_test_df = pd.read_csv('/content/drive/MyDrive/L3Cube/L3Cube-MahaSent-MD/MahaSent_ST/MahaSent_ST_Test.csv')\n",
        "print(\"MahaSent_ST Test DataFrame loaded successfully.\")\n",
        "print(st_test_df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MahaSent_ST Test DataFrame loaded successfully.\n",
            "   Unnamed: 0                                       marathi_text  label\n",
            "0           0                                       मोनिका नाही!     -1\n",
            "1           1  मला भीती वाटते की परिस्थिती आमच्या अपेक्षेपेक्...     -1\n",
            "2           2            अरे, तुमच्याकडे आधीपासून सर्वकाही नाही.     -1\n",
            "3           3                  जॉय, तिच्यावर मारहाण करणे थांबवा.     -1\n",
            "4           4                                 अरे देवा, हे बघ...     -1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "028cc11c2b1f430ab8bc2f9ffd69216d",
            "a6d8fd3d8ac1480c93ce7c2352951c55",
            "899a96ad97f64366853eb58e1a5d75fc",
            "91d491dc2eb7470aacde10830cdb522d",
            "d2c512888e8b4013a4754650a09f96b6",
            "d3aa2d7986bb485991c67eddc573e878",
            "252c03f2cdad4ce39f89ec3743067abf",
            "cbae8e6ac2f844829e4217e177b150fa",
            "06b4186e456540b0bd5f061f68a6dcf5",
            "93fbb5d894084a47ae25ae98fb476ba2",
            "40de158e6db5423fa0660b0c10c59140"
          ]
        },
        "id": "41b0946b",
        "outputId": "ba17994a-2fc0-4455-8711-4c668f4f708d"
      },
      "source": [
        "st_test_df_processed = st_test_df.copy()\n",
        "st_test_df_processed = st_test_df_processed.rename(columns={\"marathi_text\": \"text\"})\n",
        "st_test_df_processed['label'] = st_test_df_processed['label'].astype(int)\n",
        "st_test_df_processed['label'] = st_test_df_processed['label'] + 1 # -1->0, 0->1, 1->2\n",
        "st_test_df_processed['text'] = st_test_df_processed['text'].astype(str).fillna('')\n",
        "st_test_dataset = Dataset.from_pandas(st_test_df_processed)\n",
        "st_test_encoded = st_test_dataset.map(tokenize_fn, batched=True)\n",
        "\n",
        "print(\"MahaSent_ST Test DataFrame processed and encoded successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "028cc11c2b1f430ab8bc2f9ffd69216d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MahaSent_ST Test DataFrame processed and encoded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "dfb013c0",
        "outputId": "55187db9-2fd2-4774-b9de-da259dcf26c8"
      },
      "source": [
        "st_test_metrics = trainer.evaluate(st_test_encoded)\n",
        "print(\"MahaSent_ST Test metrics:\", st_test_metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='658' max='188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [188/188 46:32]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MahaSent_ST Test metrics: {'eval_loss': 0.6132848858833313, 'eval_accuracy': 0.7593333333333333, 'eval_precision_macro': 0.7719336452338564, 'eval_recall_macro': 0.7593333333333333, 'eval_f1_macro': 0.7614096864458851, 'eval_runtime': 5.4914, 'eval_samples_per_second': 273.156, 'eval_steps_per_second': 17.118, 'epoch': 3.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluate on MahaSent_PT Test Dataset**"
      ],
      "metadata": {
        "id": "NNO6aWvOh_1Z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98eb2619",
        "outputId": "8afbf7bf-2a05-4c02-c18f-f82cc7da2e34"
      },
      "source": [
        "pt_test_df = pd.read_csv('/content/drive/MyDrive/L3Cube/L3Cube-MahaSent-MD/MahaSent_PT/tweets-test.csv')\n",
        "print(\"MahaSent_PT Test DataFrame loaded successfully.\")\n",
        "print(pt_test_df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MahaSent_PT Test DataFrame loaded successfully.\n",
            "                                               tweet  label\n",
            "0  चा फक्त नारा देऊन उपयोग नाही. महिला अत्याचाराच...      1\n",
            "1  पेट्रोल आणि डिझेलवर एक रूपया अधिभार लावल्याने ...     -1\n",
            "2  लूट झूट का राज भागावो, \\nरोजगार और विकास लावो....      1\n",
            "3  महाराष्ट्र विकास आघाडी सरकारच्या मंत्रिमंडळ वि...      1\n",
            "4  पिंपरीत अॅथलेटिक्स आणि विविध क्षेत्रांतल्या खे...      1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "96bf95ff1ac746fdbbc1cc93e62447ff",
            "15635b820f54405193fdb829a07fd45f",
            "d0b28614bd4d459992ec2a8bfe98adcc",
            "0b3ea73ff910440eae8130b9359b016a",
            "dbd9723f5e624911b4f455e916797e56",
            "fd2090e164a0475bb0c7f5a1579093d9",
            "ba03dd30f8934f4c96916f4d884e2076",
            "2d600bae3775441fbc1b407167234ce1",
            "ab853b17ae5a4d629b964938795cdc4f",
            "c838cb112706440bb8de8ef27965cb32",
            "3ba667dae6a146fb8cbaab9ed44ee30a"
          ]
        },
        "id": "3b8dada9",
        "outputId": "f8a3398e-fad5-41b5-a7d9-2ed40ee949c0"
      },
      "source": [
        "pt_test_df_processed = pt_test_df.copy()\n",
        "pt_test_df_processed = pt_test_df_processed.rename(columns={\"tweet\": \"text\"})\n",
        "pt_test_df_processed['label'] = pt_test_df_processed['label'].astype(int)\n",
        "pt_test_df_processed['label'] = pt_test_df_processed['label'] + 1 # -1->0, 0->1, 1->2\n",
        "pt_test_df_processed['text'] = pt_test_df_processed['text'].astype(str).fillna('')\n",
        "pt_test_dataset = Dataset.from_pandas(pt_test_df_processed)\n",
        "pt_test_encoded = pt_test_dataset.map(tokenize_fn, batched=True)\n",
        "\n",
        "print(\"MahaSent_PT Test DataFrame processed and encoded successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2250 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96bf95ff1ac746fdbbc1cc93e62447ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MahaSent_PT Test DataFrame processed and encoded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "3c7a8151",
        "outputId": "4df133cd-651d-4309-8a7b-df9e7dc0a2b5"
      },
      "source": [
        "pt_test_metrics = trainer.evaluate(pt_test_encoded)\n",
        "print(\"MahaSent_PT Test metrics:\", pt_test_metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='799' max='188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [188/188 47:22]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MahaSent_PT Test metrics: {'eval_loss': 0.6292356252670288, 'eval_accuracy': 0.7351111111111112, 'eval_precision_macro': 0.7524694571224829, 'eval_recall_macro': 0.7351111111111112, 'eval_f1_macro': 0.7300345337163829, 'eval_runtime': 7.4323, 'eval_samples_per_second': 302.733, 'eval_steps_per_second': 18.971, 'epoch': 3.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"MahaSent_MR Test Accuracy: {mr_test_metrics['eval_accuracy']:.4f}\")\n",
        "print(f\"MahaSent_PT Test Accuracy: {pt_test_metrics['eval_accuracy']:.4f}\")\n",
        "print(f\"MahaSent_GT Test Accuracy: {gt_test_metrics['eval_accuracy']:.4f}\")\n",
        "print(f\"MahaSent_ST Test Accuracy: {st_test_metrics['eval_accuracy']:.4f}\")"
      ],
      "metadata": {
        "id": "YdPTzRDAwfWJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}